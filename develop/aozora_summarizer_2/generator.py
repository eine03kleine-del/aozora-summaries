import os
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm
from transformers import pipeline

# ==========================================
# è¨­å®š
# ==========================================
BASE_URL = "https://www.aozora.gr.jp/"
SAVE_DIR = "summaries"
os.makedirs(SAVE_DIR, exist_ok=True)

# è¦ç´„ãƒ¢ãƒ‡ãƒ«ï¼ˆæ—¥æœ¬èªå¯¾å¿œãƒ»è»½é‡ï¼‰
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# ==========================================
# é–¢æ•°ç¾¤
# ==========================================

def get_author_list():
    """é’ç©ºæ–‡åº«ã®ä½œå®¶ä¸€è¦§ã‚’å–å¾—"""
    url = BASE_URL + "index_pages/person_all.html"
    res = requests.get(url)
    res.encoding = "shift_jis"
    soup = BeautifulSoup(res.text, "html.parser")

    authors = []
    for link in soup.select("ol > li > a"):
        name = link.text.strip()
        href = link.get("href")
        if href and "person" in href:
            authors.append((name, BASE_URL + href))
    return authors


def get_works_from_author(author_url):
    """ä½œå®¶ãƒšãƒ¼ã‚¸ã‹ã‚‰ä½œå“ä¸€è¦§ã‚’å–å¾—"""
    res = requests.get(author_url)
    res.encoding = "shift_jis"
    soup = BeautifulSoup(res.text, "html.parser")

    works = []
    for a in soup.select("ol > li > a"):
        title = a.text.strip()
        href = a.get("href")
        if href and "cards" in href:
            works.append((title, BASE_URL + href))
    return works


def extract_text_from_work(work_url):
    """ä½œå“ãƒšãƒ¼ã‚¸ã‹ã‚‰æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    res = requests.get(work_url)
    res.encoding = "shift_jis"
    soup = BeautifulSoup(res.text, "html.parser")

    link = soup.find("a", string="ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    if not link:
        return None

    txt_url = BASE_URL + link.get("href")
    txt_res = requests.get(txt_url)
    txt_res.encoding = "shift_jis"
    return txt_res.text


def summarize_text(text):
    """æœ¬æ–‡ã‚’è¦ç´„"""
    text = text.replace("\r", "").replace("\n", "")
    if len(text) > 3000:
        text = text[:3000]  # é•·ã™ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ‡ã‚Šè©°ã‚
    summary = summarizer(text, max_length=150, min_length=50, do_sample=False)
    return summary[0]["summary_text"]


def save_summary(author, title, summary):
    """è¦ç´„ã‚’HTMLå½¢å¼ã§ä¿å­˜"""
    safe_author = author.replace(" ", "_")
    safe_title = title.replace(" ", "_")
    author_dir = os.path.join(SAVE_DIR, safe_author)
    os.makedirs(author_dir, exist_ok=True)

    file_path = os.path.join(author_dir, f"{safe_title}.html")
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(f"<h1>{title}</h1>\n<p>{summary}</p>")

    return file_path


# ==========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==========================================

def main():
    print("ğŸŸ¦ é’ç©ºæ–‡åº«ã®ä½œå®¶ä¸€è¦§ã‚’å–å¾—ä¸­...")
    authors = get_author_list()[:5]  # ãƒ†ã‚¹ãƒˆçš„ã«ä¸Šä½5ä½œå®¶ã¾ã§ï¼ˆèª¿æ•´å¯ï¼‰

    index_entries = []

    for author, author_url in tqdm(authors, desc="Processing authors"):
        works = get_works_from_author(author_url)[:5]  # å„ä½œå®¶5ä½œå“ã¾ã§
        author_page = os.path.join(SAVE_DIR, author.replace(" ", "_") + ".html")

        author_entries = []
        for title, work_url in works:
            try:
                text = extract_text_from_work(work_url)
                if not text:
                    continue
                summary = summarize_text(text)
                path = save_summary(author, title, summary)
                rel_path = os.path.relpath(path, SAVE_DIR)
                author_entries.append(f"<li><a href='{rel_path}'>{title}</a></li>")
            except Exception as e:
                print(f"âš ï¸ {title} ã®è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        # ä½œå®¶ãƒšãƒ¼ã‚¸HTMLç”Ÿæˆ
        with open(author_page, "w", encoding="utf-8") as f:
            f.write(f"<h1>{author}</h1>\n<ul>\n")
            f.write("\n".join(author_entries))
            f.write("\n</ul>")

        index_entries.append(f"<li><a href='{author.replace(' ', '_')}.html'>{author}</a></li>")

    # index.htmlä½œæˆ
    with open("index.html", "w", encoding="utf-8") as f:
        f.write("<!DOCTYPE html><html lang='ja'><head><meta charset='UTF-8'><title>é’ç©ºæ–‡åº« è¦ç´„ã¾ã¨ã‚</title></head><body>")
        f.write("<h1>é’ç©ºæ–‡åº« è¦ç´„ã¾ã¨ã‚</h1>\n<ul>\n")
        f.write("\n".join(index_entries))
        f.write("\n</ul></body></html>")

    print("âœ… ã™ã¹ã¦å®Œäº†ã—ã¾ã—ãŸã€‚index.html ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


if __name__ == "__main__":
    main()
